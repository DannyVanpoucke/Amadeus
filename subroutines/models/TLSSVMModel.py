# -*- coding: utf-8 -*-
"""
Created on Mon May 20 16:58:55 2020

Least Squares Support Vector Machine. This wrapper class is build upon
my own LS-SVM regression class in the LSSVMlib folder.

@author: Dr. Dr. Danny E. P. Vanpoucke
@web   : https://dannyvanpoucke.be
"""
import sys
sys.path.append("subroutines/LSSVMLib")

import pandas as pd
from TModelClass import TModelClass
import numpy as np
from TModelResults import TModelResults
from Bootstrap import TBootstrap, Bootstrap_1Col
from TModelQualityData import TModelQualityData
from sklearn.pipeline import Pipeline
from sklearn.exceptions import ConvergenceWarning

class TLSSVMModel(TModelClass):
    """
    Child class representing the LS-SVM regression model
    """
    def __init__(self,name,Target, Feature: pd.DataFrame, 
                 Target_test, Feature_test: pd.DataFrame,
                 Pipeline: Pipeline,
                 EnsemblePipeline: Pipeline,
                 Gamma:float=1.0, Kernel:str=None, 
                 Degree:float=2, Sigma:float=1.0,
                 CrossVal: int=5):
        """
        Constructor to set up a polynomial model with Lasso Regularisation. The Alpha 
        values are obtained via cross-validation. 100 alpha values are checked along the path.
    
        parameters:
         - name : the name of the object instance
         - Feature : The features to use & transform
         - Target     : the training target data
         - Target_test: the test target data
         - Feature_test: the untransformed features for testing.
         - Pipeline : a pipeline generated by the PipelineFactory
         - EnsemblePipeline : the pipeline generated by the PipelineFactory for the entire ensemble dataset
         - Gamma : The LS-SVM hyperparameter Gamma (float), DEFAULT=1.0 
         - Kernel : string with the kernel name (the 'second' hyperparameter: {'linear','poly','rbf'}, DEFAULT='rbf'
         - Degree  : The polynomial degree in case a 'poly'-kernel is used (float), DEFAULT=2
         - Sigma : Scaling factor used by both the 'poly'- and 'rbf' kernel
                     (float), DEFAULT=1.0
         - CrossVal: How-many-fold crossvalidation is required for hyperparameter tuning? [DEFAULT = 5]
     
        It sets the following properties
            - pipeline : a pipeline object containing the preprocessing transformations (excluding the fitter function)
            - CVmodel  : the fitter function to be used (should be an sklearn function with "fit" method)
            - model : The model is only set once the CVmodel has run a fit-operation
            - feature_tf: the transformed features as obtained by the pipeline  
            
            - parJobs : number of cores to use. Go full parallel on serial case, and single core on parallel code
        parameters sets for accounting/tracking purposes
            - crossVal : the Crossvalidation model/size (=CrossVal parameter) 
            - bestGamma: best Gamma-hyperparameter as obtained by our grid search
            - bestSigma: best Sigma-hyperparameter as obtained by our grid search
            
            - cv_iter : number of iterations needed 
            - cv_warns: %-number of convergence-warnings thrown during grid search
            
        """
        from LSSVMRegression import LSSVMRegression
        from sklearn.model_selection import GridSearchCV
        from multiprocessing import current_process
    
        super().__init__(name,Target, Feature,Target_test, Feature_test)
        
        if current_process().name == 'MainProcess':
            print('Hello from the main process')
            self.parJobs=-1
        else:
            print('Hello from child process')
            self.parJobs=1
        
        
        self.nameModel='LS-SVM Regression'
        self.name=name
        print("Initialising the child class:",self.nameModel)
        #create a pipeline (can be extended to contain more functions, p67)
        self.pipeline = Pipeline
        self.EnsPipe = EnsemblePipeline      
        self.feature_tf = self.pipeline.fit_transform(Feature) #this is a numpy array...

        #track the lists of possible hyper-parameter values
        self.n_gammas=13 # the grid for the gamma values
        self.gammas=[1.0e-6,1.0e-5,1.0e-4,1.0e-3,1.0e-2,0.1,1.0,10.0,100.0,1.0e3,1.0e4,1.0e5,1.0e6]
        self.n_sigmas=13 # the grid for the sigma/c values (in case of rbf and poly)
        self.sigmas=[1.0e-6,1.0e-5,1.0e-4,1.0e-3,1.0e-2,0.1,1.0,10.0,100.0,1.0e3,1.0e4,1.0e5,1.0e6]
        
        if Kernel is None:#set default
            Kernel='rbf'
        
        self.kernel=Kernel
        self.gamma=Gamma
        self.degree=Degree
        self.sigma=Sigma
        params=dict() #empty dict...it will be set during fitting
        #params['c']=[self.sigma] #needs to be a sequence        
        #params['d']=[self.degree]
        #params['gamma']=self.gammas      
        #params['kernel']=[self.kernel]        
        params['sigma']=self.sigmas        
        
#        params['estimator__c']=[self.sigma] #needs to be a sequence        
#        params['lssvmregression__c']=[self.sigma] #needs to be a sequence        

        lssvm = LSSVMRegression(
                         #alphas=self.alphas, #set the alphas automatically
                         gamma=self.gamma,  #the first hyper-param of LS-SVM, for all kernels
                         kernel=self.kernel,#the kernel to be used
                         c=self.sigma,      #the scale-factor in case of a poly kernel
                         d=self.degree,     #maximum degree for poly kernel
                         sigma=self.sigma,  #the scale factor of the rbf kernel
                         )
        self.CVmodel = GridSearchCV(
                lssvm, # our estimator
                param_grid=params, # dictionary with our possible hyper-parameters
                scoring='neg_mean_squared_error', #This gives the same type of scoring as the lasso CV
                n_jobs=self.parJobs, #if you use -1 (= go parallel over all cores), you can not suppress the annoying convergence warning
                cv=CrossVal,
                error_score=np.nan, # if set to raise it throws a error in case one point dies, now it throws a warning "FitFailedWarning"
                return_train_score=True, # why would we not be interested in the result of the training scores?
                )
        
        #print("DEBUG params INIT:",self.CVmodel.get_params())
        
        #to keep track of some options:
        self.crossVal=CrossVal
        self.bestGamma=0
        self.bestSigma=0
        self.cv_iter=0
        self.cv_warns=0 # %-number of warnings thrown during ElasticNetCV = #warnings/(#alphas * #l1_ratio)
        self.model=None
        self.coefUsage=None # contains the % of non-zero values of each coefficient over the model instances of the ensemble, is set upon creation of the average
        self.coefInEnsemble=None # contains the % of this coefficient present in an ensemble
        self.sklCVfail=False # are there reasons to believe the sk-learn CV failed miserably?
    
    #@ignore_warnings(category=ConvergenceWarning)  
    def __hyperTune(self):
        """
            Function which tunes the two hyperparameters as cheaply as possible
            
        """
        import warnings
        import numpy as np
        params=dict()
        paramGrid=dict()
        # scores are negative values, with the best having the least negative value...hence we search the max
        #chances are this will depend on the kernel-function selected
        if (self.kernel=="rbf"):
            print("LS-SVM: Hyperparameter tuning for rbf kernel.")
            Gamma=10.0
            Sigma=10.0
            NotGood=True
            #1) Gamma-constant Line, logscale
            while NotGood:
                Gamma=Gamma*10.0 #start at 100
                params['gamma']=[Gamma]       #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                params['sigma']=self.sigmas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                paramGrid['param_grid']=params
                self.CVmodel.set_params(**paramGrid)      #clean way to update the model as we only wish to change the sigmas with fixed Gamma=100
                #print("====== DEBUG BEFORE CVGRID RUN=====")
                with warnings.catch_warnings(record=True) as caught_warnings:
                    warnings.simplefilter("always",category=ConvergenceWarning)
                    self.CVmodel.fit(self.feature_tf,self.target)
                warnCount=len(caught_warnings)
                
                #print("DEBUG params",self.CVmodel.get_params())
                refv=self.CVmodel.cv_results_['mean_test_score'][np.argmin(self.CVmodel.cv_results_['param_sigma'])]
                minv=np.amax(self.CVmodel.cv_results_['mean_test_score'])
                Sigma=self.CVmodel.cv_results_['param_sigma'][np.argmax(self.CVmodel.cv_results_['mean_test_score'])]
                NotGood=(((minv/refv)>0.7)and(Gamma<1.0E6)) # Gamma=1M is upper limit
            #2) Next: Semilin around best Sigma
            #print("1. (GAMMA,SIGMA)=",Gamma,",",Sigma,"-->",np.amax(self.CVmodel.cv_results_['mean_test_score']))
            self.sigmas=list(i*0.1*Sigma for i in range(1,10))
            self.sigmas.extend(list(i*Sigma for i in range(1,10)))
            self.n_sigmas=18
            params['gamma']=[Gamma]       #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
            params['sigma']=self.sigmas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
            paramGrid['param_grid']=params
            self.CVmodel.set_params(**paramGrid)
                
            with warnings.catch_warnings(record=True) as caught_warnings:
                warnings.simplefilter("always",category=ConvergenceWarning)
                self.CVmodel.fit(self.feature_tf,self.target)
            warnCount=warnCount+len(caught_warnings)    
            Sigma=self.CVmodel.cv_results_['param_sigma'][np.argmax(self.CVmodel.cv_results_['mean_test_score'])]
            #3) with fixed Sigma, find step in Gamma
            #print("2. (GAMMA,SIGMA)=",Gamma,",",Sigma,"-->",np.amax(self.CVmodel.cv_results_['mean_test_score']))
            params['gamma']=self.gammas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
            params['sigma']=[Sigma]     #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
            paramGrid['param_grid']=params
            self.CVmodel.set_params(**paramGrid)
                
            with warnings.catch_warnings(record=True) as caught_warnings:
                warnings.simplefilter("always",category=ConvergenceWarning)
                self.CVmodel.fit(self.feature_tf,self.target)
            warnCount=warnCount+len(caught_warnings)    
            Gammas=self.CVmodel.cv_results_['param_gamma']
            nGammas=len(Gammas)
            Quals=self.CVmodel.cv_results_['mean_test_score']*-1.0
            startDecline=False
            stepPos=-1
            for nr in range(nGammas-1):
                diff=Quals[nr+1]-Quals[nr]
                if ((diff<0.0)and(abs(diff)>0.05*Quals[nr])):
                    startDecline=True
                    stepPos=nr+1 #to prevent issues if the step were to be at the upper edge
                elif startDecline==True :# end of the decline
                    stepPos=nr+1
                    break
            #normally we should have found a step...what to do if we did not?
            if (stepPos>0):
                #4) semilin around best Gamma...and take the "lowest" error
                Gamma=Gammas[nr+1]
                #print("3. (GAMMA,SIGMA)=",Gamma,",",Sigma,"-->",np.amax(self.CVmodel.cv_results_['mean_test_score']))
            
                self.gammas=list(i*0.1*Gamma for i in range(1,10))
                self.gammas.extend(list(i*Gamma for i in range(1,10)))
                self.n_gammas=18
                params['gamma']=self.gammas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                params['sigma']=[Sigma]     #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                paramGrid['param_grid']=params
                self.CVmodel.set_params(**paramGrid)
                
                with warnings.catch_warnings(record=True) as caught_warnings:
                    warnings.simplefilter("always",category=ConvergenceWarning)
                    self.CVmodel.fit(self.feature_tf,self.target)
                warnCount=warnCount+len(caught_warnings)    
                Gamma=self.CVmodel.cv_results_['param_gamma'][np.argmax(self.CVmodel.cv_results_['mean_test_score'])]
                #5) and finally a 10x10 grid around the best Gamma and Sigma
                #print("4. (GAMMA,SIGMA)=",Gamma,",",Sigma,"-->",np.amax(self.CVmodel.cv_results_['mean_test_score']))
                self.gammas=list(i*0.2*Gamma for i in range(1,10))
                self.n_gammas=9
                self.sigmas=list(i*0.2*Sigma for i in range(1,10))
                self.n_sigmas=9
                params['gamma']=self.gammas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                params['sigma']=self.sigmas #the estimator__ prefix is because we are calling the set-params of gridsearchCV and not the LSSVM
                paramGrid['param_grid']=params
                self.CVmodel.set_params(**paramGrid)
                
                with warnings.catch_warnings(record=True) as caught_warnings:
                    warnings.simplefilter("always",category=ConvergenceWarning)
                    self.CVmodel.fit(self.feature_tf,self.target)
                warnCount=warnCount+len(caught_warnings)    
                #print('BEST-PARAMS=',self.CVmodel.best_params_,"\n BEST-INDEX=",self.CVmodel.best_index_,"\n BEST-SCORE=",self.CVmodel.best_score_,"\n BEST-EST=",self.CVmodel.best_estimator_)
                Gamma=self.CVmodel.best_params_['gamma']
                Sigma=self.CVmodel.best_params_['sigma']
                
            #print("FINAL (GAMMA,SIGMA)=",Gamma,",",Sigma,"-->",np.amax(self.CVmodel.cv_results_['mean_test_score']))
            self.bestGamma=Gamma
            self.bestSigma=Sigma
        else:
            print("LS-SVM: Hyperparameter tuning for OTHER kernel.")
            #needs implementation
            
            
    
    
    #@ignore_warnings(category=ConvergenceWarning)    
    def fit(self):
        """
        Class-method wrapping the fit-method of the sklearn model
           - Target : a pandas dataframe with the Target data belonging to the 
                   Features provided upon initialisation.
        """
        import warnings
        from LSSVMRegression import LSSVMRegression
        
        self.__hyperTune()
        
        self.model = LSSVMRegression(
                         #alphas=self.alphas, #set the alphas automatically
                         gamma=self.bestGamma,  #the first hyper-param of LS-SVM, for all kernels
                         kernel=self.kernel,#the kernel to be used
                         c=self.bestSigma,      #the scale-factor in case of a poly kernel
                         d=self.degree,     #maximum degree for poly kernel
                         sigma=self.bestSigma,  #the scale factor of the rbf kernel
                         )
        
        #print("=== MODEL WAS OPT HERE : best gamma=",self.bestGamma,
        #      " in [",self.CVmodel.get_params()['param_grid']['gamma'][0],", ",self.CVmodel.get_params()['param_grid']['gamma'][-1],"] ",
        #      " n-gamma=",self.n_gammas)
        print("=== MODEL WAS OPT HERE : best sigma=",self.bestSigma,
              " in [",self.CVmodel.get_params()['param_grid']['sigma'][0],", ",self.CVmodel.get_params()['param_grid']['sigma'][-1],"] ",
              " n-sigma=",self.n_sigmas)
        #print(na,": #WARN-->",warnCount,'/',totcnt," : ",self.cv_warns," % | a=",self.bestAlpha," r1=",self.bestL1_ratio)
        #print(" %5i : #WARN--> %5i / %5i : %9.4f %%  | a=  %9.4f  r1=  %9.4f "%(na,warnCount,totcnt,self.cv_warns,self.bestAlpha,self.bestL1_ratio) )
        with warnings.catch_warnings(record=True):
            warnings.simplefilter("always",category=ConvergenceWarning)
            self.model.fit(self.feature_tf,self.target)
        self.setCoefficients()
        print("did some fitting, Parent-style:",type(self.model).__name__)
              
              
    #@ignore_warnings(category=ConvergenceWarning)   
    def fitSanityCheck(self)->int:
        """
        Class method which should cover/deal with failures of sklearn.
        
        No issues known at the moment, so will return 0 by default        
        
        """
        cnt=0
        return cnt

#paralel 
    def setAverageCoefficients(self, EnsembleData: TModelResults, setCI: bool):
        """
        Use the ensemble data to create an "average" model, and set the "coefficients"
        in the current model. This should be performed in each model separately
        
            NOTE: We assume 
                1. that the support vectors(/features) were indexed with a 
                   sequence of INTEGER values starting at 0.
                2. the same sequence and order are used for all subsets drawn 
                   in the ensemble.
                3. that the largest value of the sequence is the size of the 
                   set of support vectors (-1, because caounting starts at 0)
                  
        
        --> needs to include hyper paramaters...how do we deal with multi-preference?
        
        """
        from LSSVMRegression import LSSVMRegression
        import multiprocessing as mp
        from HPCTools import get_num_procs
        
        # 0. Find out how many coefficients/data-points there are
        FullSet=set()
        for i in range(EnsembleData.NData):
            FullSet.update(set(EnsembleData.modelCoef[i]['data_pt_index'][1].flatten())) #flatten because nd-array
        SizeSet=max(FullSet)+1 #if for some reason some support vectors are missing altogether
        #size of a support vector
        SVar=EnsembleData.modelCoef[0]['support_'][1]
        SizeSV=len(SVar[0])
        
        # 1. Calculate the average coefficients
        # 1.1. transform them to arrays
        #start = time.perf_counter_ns()
        #print("3.1) Average Coefficients : AVG")
        self.coefUsage=np.zeros(SizeSet)
        self.coefInEnsemble=np.zeros(SizeSet)
        
        intercept=np.zeros(EnsembleData.NData)
        coef=np.zeros((EnsembleData.NData,SizeSet))
        support_vectors_sorted=np.zeros((SizeSet,SizeSV))
        sigmas=np.zeros(EnsembleData.NData)
        gammas=np.zeros(EnsembleData.NData)
        for i in range(EnsembleData.NData):
            mcf=EnsembleData.modelCoef[i]
            intercept[i]=np.asarray(mcf['intercept_'][1]).flatten() #use flatten, this returns a copy, ravel, does not, and you may end up modifying the original data
            stra=mcf['sigma'][1]
            sigmas[i]=stra.split()[3]
            stra=mcf['gamma'][1]
            gammas[i]=stra.split()[3]
            #coefficients are linked to "support-vectors" so we need to make sure we average the
            #  coef. of the same support vectors of different ensembles
            coefar=np.asarray(mcf['coef_'][1]).flatten()
            idxar=mcf['data_pt_index'][1].flatten()
            if (FullSet != set()):
                SVar=mcf['support_'][1]
            for j in range(mcf['coef_'][1].shape[1]):
                coef[i,idxar[j]]=coefar[j]
                self.coefInEnsemble[idxar[j]] += 1
                if idxar[j] in FullSet: #complicated way of only setting these values once
                    support_vectors_sorted[idxar[j]]=SVar[j]
                    FullSet.remove(idxar[j])
                    
        for j in range(SizeSet):
            self.coefUsage[j]=100.0*(np.count_nonzero(coef[:,j])/EnsembleData.NData) # The %-fraction of non-zero versions of each coefficient
            self.coefInEnsemble[j]=100.0*(self.coefInEnsemble[j]/EnsembleData.NData) # The fraction of the presence of the support vector in the ensemble (upper bound for self.coefUsage)
        
        self.bestGamma=np.mean(gammas,axis=0)
        self.bestSigma=np.mean(sigmas,axis=0)
        mean_intercept=np.mean(intercept,axis=0)#axis is the varying direction, so 0 means we calculate the average of a column by varying the row
        mean_coef=np.mean(coef,axis=0) 
        # 2. Set the model coefficients to these averaged values
        # LS-SVM is under our full control so we have some more
        # power to do what is needed
        ## --> FIRST: Create the "model"
        self.model = LSSVMRegression(
                         gamma=self.bestGamma,  #the first hyper-param of LS-SVM, for all kernels
                         kernel=self.kernel,    #the kernel to be used, which we still have from the original init
                         c=self.bestSigma,      #the scale-factor in case of a poly kernel
                         d=self.degree,     #maximum degree for poly kernel
                         sigma=self.bestSigma,  #the scale factor of the rbf kernel
                         )
        ## --> now we set the average coefficients and support vectors
        param=dict()
        param['intercept_']=mean_intercept
        param['coef_']=mean_coef
        param['support_']=support_vectors_sorted
        self.model.set_attributes(**param)
        #make sure we know it is an average model
        self.isAverage = True
        self.hasCI=False
        #print("get_state post setting=",self.model.__getstate__())
        
        if setCI:
            #end = time.perf_counter_ns()
            #print("3.2.a) Average Coefficients : CI Intercept ",(end-start)/10E9)
            # 3. Calculate Confidence Interval using Bootstrapper tech?
            # & 4. Store the CI data
            ## For the intercept
            boot=TBootstrap(data=intercept,Func=np.mean)
            #end = time.perf_counter_ns()
            #print("3.2.b) NPboot",(end-start)/1E9)
            boot.NPbootstrap(n_iter=2000, Jackknife=True)
            #end = time.perf_counter_ns()
            #print("3.2.c) Con Int",(end-start)/1E9)
            avgm, avgp = boot.ConfidenceInterval(CItype="BCa",alpha=0.05,n_samples=2000)#95%confidence interval
            self.CI["intercept_lo"]=avgm
            self.CI["intercept_hi"]=avgp
            print("===BOOT INTERCEPT:",avgm,avgp)
            
            ## For the coefficients
            # Parallelisation for sections performing bootstraps. 
            # Parallelization at the highest level of a column, 
            # ??Is the overhead sufficiently low to have benefits?
            # 1. create our process pool with as many processes as physical cores
            pool=mp.Pool(processes=get_num_procs(-1))
            # 2. set drones to work
            alpha=0.05 #95%confidence interval
            drones=[pool.apply_async(Bootstrap_1Col, args=(col,coef[:,col],alpha)) for col in range(SizeSet)]
            # 3. as we can not assume the cols to be produced in the correct order
            #    --> make it a dict
            ciDict=dict()
            for drone in drones:
                col,avgm,avgp=drone.get()
                ciDict[col]=list([avgm,avgp])
                
            # 4. wait untill all processes are finished
            pool.close()
            pool.join()
            # 5. and put then in the corrcet order in the list        
            avgml=list()
            avgpl=list()
            for col in range(SizeSet):
                avgml.append(ciDict[col][0])
                avgpl.append(ciDict[col][1])
                
            self.CI["coef_lo"]=avgml
            self.CI["coef_hi"]=avgpl
            self.hasCI = True
            
        #store the resulting coefficients in our wrapper tracker...and we are done
        #print("Store resulting coefficients.")
        self.setCoefficients()
        self.Quality=TModelQualityData(EData=EnsembleData)
    
    
    def printAverageCoefficients(self, File: str=None):
        """
        Print a block of information to a file, containing the averaged coefficients for the 
        LS-SVM model.
        
        --> needs to include hyper paramaters...
        
        
        parameters:
            - self:
            - File: string containing a filename, if None standard output is used. Default=None
        """       
        maxl=5
        if File is None:
            print("======= THE AVERAGED MODEL ==============")
            print(" Model : ",self.name)
            print(self.Quality.QualitiesText())
            
            if self.hasCI:
                print("Intercept  : ",f'{self.model.intercept_: 12.7f}'," and CI=[",
                       f'{self.CI["intercept_lo"]: 12.7f}'," ; ",f'{self.CI["intercept_hi"]: 12.7f}',"]")
                for col in range(len(self.model.coef_)):
                    #print("coef ",coefstr[col]," : ",self.model.coef_[col]," and CI=[",self.CI["coef_lo"][col]," ; ",self.CI["coef_hi"][col],"]")
                    print("coef SV",f'{col: <{maxl}}'," : ",f'{self.model.coef_[col]: 12.7f}',
                            " and CI=[",f'{self.CI["coef_lo"][col]: 12.7f}'," ; ",
                            f'{self.CI["coef_hi"][col]: 12.7f}',"]   usage= ",f'{self.coefUsage[col]: 8.3f}',
                            " %  | Ensemble Usage=",f'{self.coefInEnsemble[col]: 8.3f}'," % ")
            else:
                print("Intercept  : ",f'{self.model.intercept_: 12.7f}')
                for col in range(len(self.model.coef_)):
                    print("coef SV",f'{col: <{maxl}}'," : ",f'{self.model.coef_[col]: 12.7f}',
                            "   usage= ",f'{self.coefUsage[col]: 8.3f}'," %  | Ensemble Usage=",
                            f'{self.coefInEnsemble[col]: 8.3f}'," % ")
            print("====================================\n\n")
        else:
            foo=open(File,"a+",)
            foo.write("======= THE AVERAGED MODEL ==============\n")
            line=" Model : "+self.name+"\n"
            foo.write(line)
            foo.write(self.Quality.QualitiesText())
            if self.hasCI:
                line="Intercept  : "+f'{self.model.intercept_: 12.7f}'+" and CI=["+f'{self.CI["intercept_lo"]: 12.7f}'+" ; "+f'{self.CI["intercept_hi"]: 12.7f}'+"] \n"
                foo.write(line)
                for col in range(len(self.model.coef_)):
                    line="coef SV"+f'{col: <{maxl}}'+" : "+f'{self.model.coef_[col]: 12.7f}'+" and CI=["+f'{self.CI["coef_lo"][col]: 12.7f}'+" ; "+f'{self.CI["coef_hi"][col]: 12.7f}'+"]    usage= "+f'{self.coefUsage[col]: 8.3f}'+" %   | Ensemble Usage="+f'{self.coefInEnsemble[col]: 8.3f}'+" % \n"
                    foo.write(line)
            else:
                line="Intercept  : "+f'{self.model.intercept_: 12.7f}'+"\n"
                foo.write(line)
                for col in range(len(self.model.coef_)):
                    line="coef SV"+f'{col: <{maxl}}'+" : "+f'{self.model.coef_[col]: 12.7f}'+"    usage= "+f'{self.coefUsage[col]: 8.3f}'+" %   | Ensemble Usage="+f'{self.coefInEnsemble[col]: 8.3f}'+" % \n"
                    foo.write(line)
            foo.write("====================================\n\n")
            foo.close() 
    
    def setCoefficients(self):
        """
        Class-method printing the fitting coefficients for an LS-SVM regression.
        It also stores the indices of the data-set points (the first column of 
        the features dataframe). This means that the parallelization and splitting in
        TAmadeus needs to conserve the "absolute" indexing of the full dataset. If some suffeling happens
        between splits, this may destroy the coherence between the subsets.
        
        """
        import numpy as np
        super().setCoefficients()
        #--------- hyper parameters -------------------
        self.modelcoef['header_hyperparameter']=[self.coefindex,"The selected best gamma and other hyper-parameters for LS-SVM are:"]
        line="  - gamma     = %0.6f  " % (self.bestGamma )
        self.modelcoef['gamma']=[-(self.coefindex+1),line]
        line="  - sigma     = %0.6f  " % (self.bestSigma )
        self.modelcoef['sigma']=[-(self.coefindex+2),line]
        line="  - n_iter_CV = %i  " % (self.cv_iter )
        self.modelcoef['n_iter']=[-(self.coefindex+3),line]
        line="  - CV-warnings = %0.2f  %%" % (self.cv_warns )
        self.modelcoef['cv_warns']=[-(self.coefindex+4),line]
        
        #------------usual coefficients-----------------
        self.modelcoef['header_coef']=[self.coefindex+5,"The coefficients for each target (one per row) are given by:"]
        self.modelcoef['coef_']=[self.coefindex+6,np.array([self.model.coef_])]
        self.modelcoef['header_intercept']=[self.coefindex+7,"The intercepts for each target (one per row) are given by:"]
        self.modelcoef['intercept_']=[self.coefindex+8,np.array([self.model.intercept_])]
        #-----------and keep track of the index of the data-set point
        self.modelcoef['data_pt_index']=[self.coefindex+9,np.array([self.feature.index])]
        self.modelcoef['support_']=[self.coefindex+10,self.feature_tf]#feature tf is a numpy array already
        
        self.coefindex+=10
        
        

